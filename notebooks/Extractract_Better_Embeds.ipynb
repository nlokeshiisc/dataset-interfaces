{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpringlesinghal\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/raid/infolab/nlokesh/anaconda3/envs/dsi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "# comment this out if you are using the pip package\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset_interfaces import utils\n",
    "from dataset_interfaces import run_textual_inversion, run_textual_inversion_plus\n",
    "from dataset_interfaces import generate\n",
    "import dataset_interfaces.imagenet_utils as in_utils\n",
    "import dataset_interfaces.inference_utils as infer_utils\n",
    "from pathlib import Path\n",
    "\n",
    "create_confounded_dataset = True\n",
    "N = 20 # N <= 20, number of class embeddings to be learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_dfs = [] \n",
    "backgrounds = ['at night', 'in the fog', 'in the forest', 'in the rain', 'in the snow']\n",
    "for bg in backgrounds:\n",
    "    bg_file = '_'.join(bg.split())\n",
    "    df = pd.read_csv(f'/raid/infolab/nlokesh/dataset-interfaces/cache/{bg_file}_preds.csv')\n",
    "    temp_df = pd.DataFrame({'cnf':df['cnf'],'bg':bg, 'z':df['true_y']})\n",
    "    concatenate_dfs.append(temp_df)\n",
    "main_df = pd.concat(concatenate_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>bg</th>\n",
       "      <th>cnf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335</td>\n",
       "      <td>in the snow</td>\n",
       "      <td>0.972870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259</td>\n",
       "      <td>at night</td>\n",
       "      <td>0.975734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360</td>\n",
       "      <td>in the rain</td>\n",
       "      <td>0.977720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361</td>\n",
       "      <td>at night</td>\n",
       "      <td>0.978480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>294</td>\n",
       "      <td>in the forest</td>\n",
       "      <td>0.980104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>293</td>\n",
       "      <td>at night</td>\n",
       "      <td>0.980218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>362</td>\n",
       "      <td>in the rain</td>\n",
       "      <td>0.980480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>339</td>\n",
       "      <td>in the rain</td>\n",
       "      <td>0.981128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>396</td>\n",
       "      <td>in the forest</td>\n",
       "      <td>0.982140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92</td>\n",
       "      <td>in the snow</td>\n",
       "      <td>0.982318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>580</td>\n",
       "      <td>in the forest</td>\n",
       "      <td>0.997990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>786</td>\n",
       "      <td>in the rain</td>\n",
       "      <td>0.998330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>145</td>\n",
       "      <td>at night</td>\n",
       "      <td>0.998420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>105</td>\n",
       "      <td>in the snow</td>\n",
       "      <td>0.998612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>94</td>\n",
       "      <td>in the snow</td>\n",
       "      <td>0.998918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>971</td>\n",
       "      <td>at night</td>\n",
       "      <td>0.999050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>340</td>\n",
       "      <td>at night</td>\n",
       "      <td>0.999182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>800</td>\n",
       "      <td>in the forest</td>\n",
       "      <td>0.999770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>476</td>\n",
       "      <td>at night</td>\n",
       "      <td>0.999810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>84</td>\n",
       "      <td>in the forest</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      z             bg       cnf\n",
       "0   335    in the snow  0.972870\n",
       "1   259       at night  0.975734\n",
       "2   360    in the rain  0.977720\n",
       "3   361       at night  0.978480\n",
       "4   294  in the forest  0.980104\n",
       "5   293       at night  0.980218\n",
       "6   362    in the rain  0.980480\n",
       "7   339    in the rain  0.981128\n",
       "8   396  in the forest  0.982140\n",
       "9    92    in the snow  0.982318\n",
       "67  580  in the forest  0.997990\n",
       "68  786    in the rain  0.998330\n",
       "69  145       at night  0.998420\n",
       "70  105    in the snow  0.998612\n",
       "71   94    in the snow  0.998918\n",
       "72  971       at night  0.999050\n",
       "73  340       at night  0.999182\n",
       "74  800  in the forest  0.999770\n",
       "75  476       at night  0.999810\n",
       "76   84  in the forest  0.999990"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_z_bg = main_df.groupby(['z','bg'])['cnf'].std().reset_index()\n",
    "std_z_bg = std_z_bg.sort_values(by='cnf',ascending=True)\n",
    "low_std_z_bg = std_z_bg[std_z_bg['cnf'] < 0.05]\n",
    "\n",
    "mean_z_bg = main_df.groupby(['z','bg'])['cnf'].mean().reset_index()\n",
    "mean_z_bg = mean_z_bg.sort_values(by='cnf',ascending=False)\n",
    "mask = mean_z_bg[['z','bg']].apply(tuple, axis=1).isin(low_std_z_bg[['z','bg']].apply(tuple, axis=1))\n",
    "mean_z_bg_low_std = mean_z_bg[mask]\n",
    "# # mean_z_bg_low_std[mean_z_bg_low_std['cnf'] < 0.99]\n",
    "# mean_z_bg_low_std\n",
    "\n",
    "mean_z = main_df.groupby(['z'])['cnf'].mean().reset_index()\n",
    "mean_z = mean_z.sort_values(by='cnf', ascending=False)\n",
    "well_understood = mean_z.head(300)\n",
    "well_understood_z = well_understood['z']\n",
    "\n",
    "z_bg_filtered = mean_z_bg_low_std[mean_z_bg_low_std['z'].isin(well_understood_z)]\n",
    "# remove z which have only one low stddev bg (so that we can choose)\n",
    "z_bg_filtered = z_bg_filtered.groupby(['z']).filter(lambda grp : len(grp) > 1)\n",
    "\n",
    "def select_bg(group):\n",
    "    return group.sample(1, random_state=0)\n",
    "# now remove repeated z we select a random bg for each z\n",
    "select_z_bg = z_bg_filtered.groupby(['z'])[['bg','cnf']].apply(select_bg).sort_values(by='cnf')\n",
    "\n",
    "select_z_bg = select_z_bg.reset_index().drop('level_1', axis=1)\n",
    "top_z_bg = select_z_bg.head(10)\n",
    "bottom_z_bg = select_z_bg.tail(10)\n",
    "top_z_beta = pd.concat([top_z_bg, bottom_z_bg])\n",
    "top_z_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_interfaces.imagenet_utils import *\n",
    "\n",
    "def idx_to_foldername(idx):\n",
    "    if idx != 0:\n",
    "        return IMAGENET_IDX_TO_SYNSET[f'{idx}']['id']\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def idx_to_label(idx):\n",
    "    return IMAGENET_IDX_TO_SYNSET[f'{idx}']['label'].split(',')[0]\n",
    "    # return IMAGENET_COMMON_CLASS_NAMES[idx]\n",
    "\n",
    "def spaces_to_underscores(label):\n",
    "    '''\n",
    "    use for converting label / background strings to file names\n",
    "    '''\n",
    "    return '_'.join(label.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_star_path = '/raid/infolab/nlokesh/dataset-interfaces/data/imagenet_star/'\n",
    "confounded_dataset_path = os.path.join(imagenet_star_path, 'confounded_dataset/')\n",
    "for z_idx, beta_string in zip(top_z_beta['z'], top_z_beta['bg']):\n",
    "    bg_path_local = spaces_to_underscores(beta_string)\n",
    "    bg_path = os.path.join(imagenet_star_path, bg_path_local)\n",
    "    foldername = idx_to_foldername(z_idx)\n",
    "    img_path = os.path.join(bg_path, foldername, '00.jpg')\n",
    "    if not os.path.exists(img_path):\n",
    "        img_path = os.path.join(bg_path, foldername, foldername, '00.jpg')\n",
    "\n",
    "    from_address = img_path\n",
    "    if not os.path.exists(os.path.join(confounded_dataset_path, bg_path_local, str(z_idx))):\n",
    "        os.makedirs(os.path.join(confounded_dataset_path, bg_path_local, str(z_idx)))\n",
    "    to_address = os.path.join(confounded_dataset_path, bg_path_local, str(z_idx), f'00.jpg' )\n",
    "    if create_confounded_dataset == True:\n",
    "        shutil.copy(from_address, to_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently hardcoded to 'confounded_dataset' folder\n"
     ]
    }
   ],
   "source": [
    "# Now that we have constructed the training dataset with confounding between beta and z, let us try to learn embeddings z*\n",
    "print(\"Currently hardcoded to 'confounded_dataset' folder\")\n",
    "IMAGENET_ROOT = \"/raid/infolab/nlokesh/dataset-interfaces/data/imagenet_star/confounded_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a subset of ImageNet classes\n",
    "classes = list(top_z_beta['z'])\n",
    "betas = list(top_z_beta['bg'])\n",
    "confidences = list(top_z_beta['cnf'])\n",
    "class_names = [IMAGENET_COMMON_CLASS_NAMES[c] for c in classes]\n",
    "tokens = [f\"<{class_names[i]}-{i}>\" for i in range(len(class_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where to store an encoder, which we will load in with the learned tokens\n",
    "T = 3000\n",
    "encoder_root = \"./encoder_root/dsi_w_high_contrast\"\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "embeds, cnf_error = run_textual_inversion_plus(IMAGENET_ROOT,\n",
    "tokens = tokens,\n",
    "z_objects = classes,\n",
    "betas = betas,\n",
    "confidences=confidences,\n",
    "z_names = class_names,\n",
    "max_train_steps = T,\n",
    "weights = [1, 1, 1]\n",
    ")\n",
    "\n",
    "infer_utils.create_encoder(embeds=embeds, tokens=tokens, class_names=class_names, encoder_root=encoder_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_beta_path(train_path, z_idx, beta):\n",
    "        path_string = os.path.join(train_path, \"_\".join(beta.split()), str(z_idx))\n",
    "        if os.path.exists(path_string):\n",
    "            return path_string\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                f\"images for the (z, beta) pair ({z_idx}, {beta}) do not exist at the expected location {path_string} \"\n",
    "            )\n",
    "train_data_dirs = [get_z_beta_path(IMAGENET_ROOT, z_idx, beta) for z_idx, beta in zip(classes, betas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where to store an encoder, which we will load in with the learned tokens\n",
    "encoder_root = \"./encoder_root/vanilla_dsi_on_confounded\"\n",
    "embeds = []\n",
    "for i in range(len(classes)):\n",
    "    \n",
    "    # runs textual inversion on a single class\n",
    "    embed = run_textual_inversion(train_data_dirs[i],\n",
    "        token = tokens[i],\n",
    "        class_name = class_names[i],\n",
    "    )\n",
    "    \n",
    "    embeds.append(embed)\n",
    "infer_utils.create_encoder(embeds=embeds, tokens=tokens, class_names=class_names, encoder_root=encoder_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
