{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/infolab/nlokesh/anaconda3/envs/dsi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "# comment this out if you are using the pip package\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset_interfaces import utils\n",
    "from dataset_interfaces import run_textual_inversion\n",
    "from dataset_interfaces import generate\n",
    "import dataset_interfaces.imagenet_utils as in_utils\n",
    "import dataset_interfaces.inference_utils as infer_utils\n",
    "from pathlib import Path\n",
    "\n",
    "create_confounded_dataset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_interfaces.imagenet_utils import *\n",
    "\n",
    "def idx_to_foldername(idx):\n",
    "    if idx != 0:\n",
    "        return IMAGENET_IDX_TO_SYNSET[f'{idx}']['id']\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "def idx_to_label(idx):\n",
    "    return IMAGENET_IDX_TO_SYNSET[f'{idx}']['label'].split(',')[0]\n",
    "    # return IMAGENET_COMMON_CLASS_NAMES[idx]\n",
    "\n",
    "def spaces_to_underscores(label):\n",
    "    '''\n",
    "    use for converting label / background strings to file names\n",
    "    '''\n",
    "    return '_'.join(label.split())\n",
    "\n",
    "if create_confounded_dataset == True:\n",
    "    # construct training set to extract embeddings\n",
    "    # introduce confounding by selecting every object under only one beta\n",
    "    # only one sample per object (in this case, object = class)\n",
    "\n",
    "\n",
    "    # list of backgrounds (beta)\n",
    "    background_strings = {\n",
    "        # 'dusk':\"at dusk\", \n",
    "        'night':\"at night\", \n",
    "        # 'sunlight':\"in bright sunlight\", \n",
    "        'fog':\"in the fog\", \n",
    "        'forest':\"in the forest\", \n",
    "        'rain':\"in the rain\", \n",
    "        'snow':\"in the snow\"\n",
    "    }\n",
    "    # number of objects Z in dataset\n",
    "    NUM_OBJECTS = len(IMAGENET_IDX_TO_SYNSET)\n",
    "    NUM_BACKGROUNDS = len(background_strings)\n",
    "    # each object gets a single background\n",
    "    background_to_objects = {} \n",
    "    np.random.seed(0)\n",
    "    objects_set = np.random.permutation(NUM_OBJECTS)\n",
    "    objects_per_bg = int(np.floor(NUM_OBJECTS/NUM_BACKGROUNDS))\n",
    "    for idx, key in enumerate(background_strings.keys()):\n",
    "        # key is a one-word descriptor of the background\n",
    "        # map non-overlapping subsets of the objects to each background\n",
    "        background_to_objects[key] = objects_set[idx*objects_per_bg : np.min([NUM_OBJECTS, (idx+1)*objects_per_bg])]\n",
    "    # construct dataset\n",
    "    imagenet_star_path = '/raid/infolab/nlokesh/dataset-interfaces/data/imagenet_star/'\n",
    "    confounded_dataset_path = os.path.join(imagenet_star_path, 'confounded_dataset/')\n",
    "    if not os.path.exists(confounded_dataset_path):\n",
    "        os.makedirs(confounded_dataset_path)\n",
    "\n",
    "\n",
    "    for key, value in background_to_objects.items():\n",
    "        bg_shorthand = key\n",
    "        bg_path_local = spaces_to_underscores(background_strings[key])\n",
    "        bg_path = os.path.join(imagenet_star_path, bg_path_local)\n",
    "        for idx in value:\n",
    "            foldername = idx_to_foldername(idx)\n",
    "            img_path = os.path.join(bg_path, foldername, '00.jpg')\n",
    "            if not os.path.exists(img_path):\n",
    "                img_path = os.path.join(bg_path, foldername, foldername, '00.jpg')\n",
    "\n",
    "            from_address = img_path\n",
    "            z_object = spaces_to_underscores(idx_to_label(idx))\n",
    "            beta = spaces_to_underscores(bg_shorthand)\n",
    "            if not os.path.exists(os.path.join(confounded_dataset_path, z_object)):\n",
    "                os.makedirs(os.path.join(confounded_dataset_path, z_object))\n",
    "            to_address = os.path.join(confounded_dataset_path, z_object, f'idx-{idx}-z-{z_object}-beta-{beta}-00.jpg' )\n",
    "            shutil.copy(from_address, to_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently hardcoded to 'confounded_dataset' folder\n"
     ]
    }
   ],
   "source": [
    "# Now that we have constructed the training dataset with confounding between beta and z, let us try to learn embeddings z*\n",
    "print(\"Currently hardcoded to 'confounded_dataset' folder\")\n",
    "IMAGENET_ROOT = \"/raid/infolab/nlokesh/dataset-interfaces/data/imagenet_star/confounded_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where to store an encoder, which we will load in with the learned tokens\n",
    "encoder_root = \"./encoder_root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a subset of ImageNet classes\n",
    "classes = range(len(IMAGENET_IDX_TO_SYNSET))\n",
    "class_names = [idx_to_label(c) for c in classes]\n",
    "tokens = [f\"<{class_names[i]}-{i}>\" for i in range(len(class_names))]\n",
    "\n",
    "# train_data_dirs = [os.path.join(IMAGENET_ROOT, \"train\", in_utils.IMAGENET_IDX_TO_SYNSET[str(c)]['id']) for c in classes]\n",
    "train_data_dirs = [os.path.join(IMAGENET_ROOT, spaces_to_underscores(idx_to_label(c))) for c in classes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n",
      " 50%|█████     | 1/2 [00:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# embeds = []\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(classes)):\n\u001b[1;32m      3\u001b[0m     \n\u001b[1;32m      4\u001b[0m     \u001b[39m# runs textual inversion on a single class\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[39m# embeds.append(embed)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     infer_utils\u001b[39m.\u001b[39;49mcreate_encoder(embeds\u001b[39m=\u001b[39;49membeds, tokens\u001b[39m=\u001b[39;49mtokens[:(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)], class_names\u001b[39m=\u001b[39;49mclass_names[:(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)], encoder_root\u001b[39m=\u001b[39;49mencoder_root[:(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)])\n",
      "File \u001b[0;32m~/dataset-interfaces/notebooks/../dataset_interfaces/inference_utils.py:82\u001b[0m, in \u001b[0;36mcreate_encoder\u001b[0;34m(embeds, tokens, class_names, encoder_root, model_name)\u001b[0m\n\u001b[1;32m     78\u001b[0m placeholder_tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtrange(\u001b[39mlen\u001b[39m(class_names)):\n\u001b[0;32m---> 82\u001b[0m     load_emb_in_token(text_encoder, tokenizer, tokens[i], embeds[i])\n\u001b[1;32m     83\u001b[0m     placeholder_tokens\u001b[39m.\u001b[39mappend(tokens[i])\n\u001b[1;32m     85\u001b[0m tokenizer\u001b[39m.\u001b[39msave_pretrained(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mencoder_root\u001b[39m}\u001b[39;00m\u001b[39m/tokenizer\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "for i in range(len(classes)):\n",
    "    \n",
    "    # runs textual inversion on a single class\n",
    "    embed = run_textual_inversion(train_data_dirs[i],\n",
    "        token = tokens[i],\n",
    "        class_name = class_names[i]\n",
    "    )\n",
    "    \n",
    "    embeds.append(embed)\n",
    "    infer_utils.create_encoder(embeds=embeds, tokens=tokens[:(i+1)], class_names=class_names[:(i+1)], encoder_root=encoder_root[:(i+1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
